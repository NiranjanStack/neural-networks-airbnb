{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to predict whether a customer will rent an entire apartment or a private room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Loading csv files\n",
    "path = os.getcwd()\n",
    "all_files = glob.glob(os.path.join(path, \"../../datasets/airbnb_survey/*2016*.csv\"))\n",
    "# all_files = glob.glob(os.path.join(path, \"airbnb_survey/*.csv\"))\n",
    "\n",
    "# Concat all csv and include city names as column\n",
    "df_each_file = (pd.read_csv(f).assign(city=os.path.basename(f).split('_')[2]) for f in all_files)\n",
    "data = pd.concat(df_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA CLEANING\n",
    "# Initial analysis of data by dataframe.info() & dataframe.describe()\n",
    "\n",
    "# Convert string date time to timestamp dtype\n",
    "data.last_modified = data.last_modified.astype('datetime64[ns]')\n",
    "\n",
    "# Dropping columns with all null values and unwanted columns\n",
    "reject_cols = ['country', 'borough', 'minstay', 'bathrooms','location','name','room_id','survey_id','latitude','longitude']\n",
    "\n",
    "for col in reject_cols:\n",
    "    try:\n",
    "        data.drop(col, axis=1, inplace=True)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "#The property_value col is null for nearly 99% of records, so dropping it\n",
    "try:\n",
    "    data.drop(['property_type'], axis=1, inplace=True)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "#Droping rows as price is null and total null records is less than 1% of population size\n",
    "if len(data[data.price.isnull()]) < len(data)*0.01:\n",
    "    data.dropna(subset=['price'], inplace=True)\n",
    "\n",
    "#Drop rows with null room_type as they won't be used in our analysis\n",
    "#In this case there are only 2 rows \n",
    "data.dropna(subset=['room_type', 'bedrooms', 'accommodates'], inplace=True)\n",
    "\n",
    "\n",
    "data.drop(data[data.price > 10000].index, inplace=True)\n",
    "\n",
    "data.drop(data[data.room_type == 'Shared room'].index, inplace=True)\n",
    "data.drop(['overall_satisfaction', 'host_id', 'last_modified', 'neighborhood'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room_type</th>\n",
       "      <th>reviews</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>aarhus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>aarhus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>aarhus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>aarhus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>aarhus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         room_type  reviews  accommodates  bedrooms  price    city\n",
       "0  Entire home/apt        0             2       1.0   68.0  aarhus\n",
       "1  Entire home/apt        1             2       0.0   61.0  aarhus\n",
       "2  Entire home/apt        1             4       1.0   68.0  aarhus\n",
       "3  Entire home/apt        5             4       2.0   87.0  aarhus\n",
       "4     Private room        1             2       1.0   61.0  aarhus"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode strings into numeric \n",
    "# Converts Entire home/apt=>0, Private room=>1, Shared room =>2\n",
    "\n",
    "labelencoder_rt = LabelEncoder()\n",
    "data.room_type = labelencoder_rt.fit_transform(data.room_type)\n",
    "\n",
    "# Does the same for city column\n",
    "labelencoder_city = LabelEncoder()\n",
    "data.city = labelencoder_city.fit_transform(data.city)\n",
    "\n",
    "y = data.iloc[:,0].values\n",
    "X = data.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Above, the values of city are replaced by 0 to 6 which implies that 2nd city is greater than 1st & \n",
    "# similarly 3rd is greater that 2nd. To solve this, we need to dummify the city column.\n",
    "# This mthod is also known as folding or melting the column.\n",
    "\n",
    "# pass the column number ([4] here) into the OneHotEncoder object\n",
    "onehotencoder = OneHotEncoder(categorical_features = [4])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "# X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del classifier\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialize neural network and add hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing Neural Network\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. output_dim: # of nodes to be added to the layer\n",
    "2. init: initialization of Stochastic Gradient Decent.In Neural Network we need to assign weights to each mode which is nothing but importance of that node. At the time of initialization, weights should be close to 0 and we will randomly initialize weights using uniform function.\n",
    "3. input_dim : # of input variables. Required only in first layer\n",
    "4. Activation: activation function to be used - relu, sigmoid etc. Neuron applies activation function to weighted. The closer the activation function value to 1 the more activated is the neuron and more the neuron passes the signal.\n",
    "    4.1 Here we are using rectifier(relu) function in our hidden layer and Sigmoid function in our output layer as we want binary result from output layer but if the number of categories in output layer is more than 2 then use SoftMax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niranjan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Niranjan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=5, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Niranjan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim =10))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 5, init = 'uniform', activation = 'relu', ))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid', ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. optimizer; algo to be used to find optimal set of weights\n",
    "2. This algorithm is Stochastic Gradient descent(SGD). Among several types of SGD algorithm the one which we will use is ‘Adam’. If you go in deeper detail of SGD, you will find that SGD depends on loss thus our second parameter is loss.\n",
    "3. Since out dependent variable is binary, we will have to use logarithmic loss function called ‘binary_crossentropy’, if our dependent variable has more than 2 categories in output then use ‘categorical_crossentropy’.\n",
    "4. We want to improve performance of our neural network based on accuracy so add metrics as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Batch size : to specify the number of observation after which you want to update weight.\n",
    "2. Epoch : total number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niranjan\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82901/82901 [==============================] - 5s 56us/step - loss: 0.3330 - acc: 0.8595\n",
      "Epoch 2/15\n",
      "82901/82901 [==============================] - 4s 50us/step - loss: 0.2664 - acc: 0.8947\n",
      "Epoch 3/15\n",
      "82901/82901 [==============================] - 5s 58us/step - loss: 0.2532 - acc: 0.8962\n",
      "Epoch 4/15\n",
      "82901/82901 [==============================] - 5s 58us/step - loss: 0.2477 - acc: 0.8970\n",
      "Epoch 5/15\n",
      "82901/82901 [==============================] - 5s 56us/step - loss: 0.2457 - acc: 0.8974\n",
      "Epoch 6/15\n",
      "82901/82901 [==============================] - 5s 56us/step - loss: 0.2449 - acc: 0.8973\n",
      "Epoch 7/15\n",
      "82901/82901 [==============================] - 5s 58us/step - loss: 0.2444 - acc: 0.8974\n",
      "Epoch 8/15\n",
      "82901/82901 [==============================] - 5s 56us/step - loss: 0.2437 - acc: 0.8977\n",
      "Epoch 9/15\n",
      "82901/82901 [==============================] - 4s 50us/step - loss: 0.2436 - acc: 0.8976\n",
      "Epoch 10/15\n",
      "82901/82901 [==============================] - 4s 53us/step - loss: 0.2433 - acc: 0.8977\n",
      "Epoch 11/15\n",
      "82901/82901 [==============================] - 5s 56us/step - loss: 0.2429 - acc: 0.8979\n",
      "Epoch 12/15\n",
      "82901/82901 [==============================] - 4s 51us/step - loss: 0.2426 - acc: 0.8972\n",
      "Epoch 13/15\n",
      "82901/82901 [==============================] - 4s 49us/step - loss: 0.2423 - acc: 0.8981\n",
      "Epoch 14/15\n",
      "82901/82901 [==============================] - 4s 50us/step - loss: 0.2417 - acc: 0.8978\n",
      "Epoch 15/15\n",
      "82901/82901 [==============================] - 4s 53us/step - loss: 0.2415 - acc: 0.8979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dea84fb2b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting our model \n",
    "classifier.fit(X_train, y_train, batch_size = 20, nb_epoch = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "\n",
    "# The prediction result will give you probability of the customer leaving the company. \n",
    "# We will convert that probability into binary 0 and 1\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_pred[:30]\n",
    "\n",
    "y_pred_bin = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15861,   817],\n",
       "       [ 1293,  2755]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89819550323265462"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (cm[0][0] + cm[1][1]) / cm.sum()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103627/103627 [==============================] - 4s 36us/step\n"
     ]
    }
   ],
   "source": [
    "scores =classifier.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 79.90%\n",
      "\n",
      "loss: 2.29\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f\" % (classifier.metrics_names[0], scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize he nodes 7 layers in neural network\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "ann_viz(classifier, title=\"Neural Netwok Viz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=network.gv.pdf width=600 height=500></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{network.gv.pdf}"
      ],
      "text/plain": [
       "<__main__.PDF at 0x1dea9171c88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view viz\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(200,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "    \n",
    "\n",
    "PDF('network.gv.pdf',size=(600,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
